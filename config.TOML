
# ["Float32", "Float64"]
precision = "Float32"

# for random seed, use "missing"
seed = 1

# ["terminal", "gui"]
# "gui" not implemented yet
display = "terminal"


[data]

# EMNIST
# ["mnist", "balanced", "digits", "bymerge", "byclass", "letters"]
# "letters" is broken
dataset = "mnist"

# ["z_score", "demean", "identity"]
preprocessing_function = "z_score"

# must add to 100
# first split is used for training
split_percentages = [80, 20]


[model]

# ["Neural_Network"]
type = "Neural_Network"

# the last layer size ("missing") is determined by the dataset
sizes = [100, "missing"]

# [xavier, he]
# he is untested
weight_initialization_functions = ["xavier", "xavier"]

use_biases = [true, false]


[layer_parameter]

# [tanh, sigmoid, identity]
# identity is untested
activation_functions = ["sigmoid", "tanh"]

# ["weight_decay", "l1", "l2"]
# default is "weight_decay"
# untested
regularization_functions = ["weight_decay", "weight_decay"]

# set to "0.0" for no regularization
# untested
regularization_rates = [0.0, 0.0]

learn_rates = [0.01, 0.1]

# layer normalization
# ["z_score", "demean", "identity"]
# not currently "plugged in"
normalization_functions = ["identity", "identity"]


[epoch_parameter]

# ["squared_error"]
cost_function = "squared_error"

# batch normalization
# ["z_score", "demean", "identity"]
normalization_function = "z_score"

number_of_epochs = 10
batch_size = 10
shuffle_data = "true"
