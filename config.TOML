
# ["Float32", "Float64"]
precision = "Float32"

# for random seed, use "missing"
seed = 1

# ["terminal", "gui"]
# "gui" not implemented yet
display = "terminal"


[dataset_parameters]

# EMNIST
# ["mnist", "balanced", "digits", "bymerge", "byclass", "letters"]
# "letters" is broken
dataset = "mnist"

# ["z_score", "demean", "identity"]
preprocessor = "z_score"

# must add to 100
# first split is used for training
split_percentages = [80, 20]


[model_parameters]

# ["NeuralNetwork"]
model = "NeuralNetwork"

# the last layer size ("missing") is determined by the dataset
sizes = [100, "missing"]

# [xavier, he]
# he is untested
weight_initializers = ["xavier", "xavier"]

use_biases = [true, false]


[layers_parameters]

# [tanh, sigmoid, identity]
# identity is untested
activators = ["sigmoid", "tanh"]

# ["weight_decay", "l1", "l2"]
# default is "weight_decay"
# untested
regularizers = ["weight_decay", "weight_decay"]

# set to "0.0" for no regularization
# untested
regularize_rates = [0.0, 0.0]

learn_rates = [0.01, 0.1]

# layer normalization
# ["z_score", "demean", "identity"]
# not currently "plugged in"
normalizers = ["identity", "identity"]


[epoch_parameters]

# ["squared_error"]
loss = "squared_error"

# batch normalization
# ["z_score", "demean", "identity"]
normalizer = "z_score"

number_of_epochs = 10
batch_size = 10
shuffle_data = "true"
